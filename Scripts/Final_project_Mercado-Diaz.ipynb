{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project - Joel A. Mercado-Diaz\n",
    "## ECEV 32000 - Introduction to Scientific Computing\n",
    "## Prof. Stefano Allesina, PhD.\n",
    "## Teaching assistants: Matthew Michalska-Smith & Elizabeth Sander\n",
    "## Winter, 2016\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My project consist of two parts. The first uses Python and Regular Expressions to manipulate the name of sequence identifiers in a FASTA file so they can be used in future phylogenetic analysis. The second part make use of R and several packages (ggplot2, dplyr, ggmap) which allow us visualize some of the geographic information contained in the FASTA file in a map.\n",
    "\n",
    "This notebook file covers the complete first part of my project and the first portion of the second one, which is completed in the other markdown provided (Final_project_Mercado-Diaz_Part2.Rmd)\n",
    "\n",
    "The files needed to run everything are stored in the folder **Data**. As you know, these should be stored in the directory from where you are running the codes. These are the files:\n",
    "\n",
    "*Final_alignment_Mercado_Sticta2.fasta*  \n",
    "*iso_3166_2_countries*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.\n",
    "\n",
    "#### Problem\n",
    "\n",
    "During my last quarter I took a class called: \"Reconstructing the Tree of Life\". For this class we were required to submit a final project that essentially asked us to make use of some of the tools learned in class to address a particular phylogenetic problem. I decided to keep it simple and took the opportunity to use some of this new knowledge for an ongoing project I had started previously which had to do with the taxonomy and phylogenetic relationship of species within the lichen genus _Sticta_ in Puerto Rico. My plan was to generate a Maximum Likelihood tree using a FASTA file that included a set of aligned sequences that I generated from my collections of this group in the island (26), in conjuction with another set of sequences from other 393 ingroup OTUs that was provided by a collaborator who is currently doing a world revision of this group. Unfortunately, when I started to handle the data I started to confront issues. According to the TA of that class, the issue could have had to do with the naming convention that my collaborator used for his sequences. The names were excesively long, for example, run this code and check the name of the output:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG NAME: >Sticta_aff_laminobeauvoisii_GBXXXXXX_DNAXXXX_JMDXXX_PuertoRico_Mercado_2246_ITS\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "############################################\n",
    "## Liz: added '../' to the open() function, because this notebook is in the Scripts folder\n",
    "## and can't get directly to Data/\n",
    "############################################\n",
    "with open(\"../Data/Final_alignment_Mercado_Sticta2.fasta\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        for keys, values in row.items():\n",
    "            while i < 1:\n",
    "                print(\"LONG NAME: \" + keys)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These names contained a diverse amount of information, from species name, voucher specimen id, collector, etc. This is what the elements of the name had:\n",
    "\n",
    "*Genus_species_GeneBankAccs#_DNAExtract#_Country_Collector_SpecimenID_Locus*\n",
    "\n",
    "I was basically getting an error when using an online tool called [Find Model](http://www.hiv.lanl.gov/content/sequence/findmodel/findmodel.html) which allows me to evaluate which nucleotide substitution model best describe my  data. Also, some file formats I was contemplating using, for example _phylyp_ format, which is required as an input file for RAxML (a free software for Maximum Likelihood phylogenetic analysis), require a short (< 10 characters) name for the sequence identifiers. I decided that perhaps was worth trying finding a way to automate the name editing of the sequences to make them shorter and therefore less clumsy.\n",
    "\n",
    "I must confess that at the end I was actually able to run a Maximum Likelihood tree by using the [Cipres computer cluster](https://www.phylo.org/). And only until recently I learned that the names lengths were not a major issue. However, my project was already underway and I learned a lot of good stuff in the process so I decided to stick with it and show the cool things I accomplished. We never now, this stuff might actually be useful for me in the future.\n",
    "\n",
    "Below I present the steps for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1. Define a function that would read the raw fasta file and return a dictionary where each key is the sequence name and the value its corresponding sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define function\n",
    "def read_fasta_file(fasta_file_path):\n",
    "    \"\"\"\n",
    "    Take a fasta file and return a dictionary where\n",
    "    each key is the name and each value is its sequence.\n",
    "    \"\"\"\n",
    "    with open(fasta_file_path, \"r\") as fasta_file:\n",
    "        fasta_dict = {}\n",
    "        seq = \"\"\n",
    "        ##########################################################\n",
    "        ## Liz: you could use the .strip() method to remove the trailing newlines and starting > character\n",
    "        ##########################################################\n",
    "        name = fasta_file.readline() # To grab the first line in the file which has a name.\n",
    "        for row in fasta_file:\n",
    "            if row[0] == \">\": # Sequence names start with this symbol which I use to identify them\n",
    "                fasta_dict[name] = seq\n",
    "                seq = \"\"\n",
    "                name = row\n",
    "            else:\n",
    "                seq += row\n",
    "\n",
    "        fasta_dict[name] = seq\n",
    "\n",
    "    return fasta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets see how this dictionary looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('>Sticta_gallowayana_KC732496_DNA4959_MON103_Colombia_Moncada_4637_ITS\\n',\n",
       " 'CGTAGGTGAACCTGCGGAAGGATCATTATCGCG--AGAGGCGTCCG----CGCCTCGGGGG------CTCCGG----CCCCCC---ACTT--CGC-A-CCC-TGTGGCT-ACT-GCACT-GGT--GTTGCTTTGGCGGCGCGTGG-CCGCC---GGAGGA---CCCGTC--AAACC-TC-TCG-AATC-G-ATGTCGTCCGAGTACC-A-TCA--TAATCGAA-TAAAAA-CTTTCAACAACGGATCTCTTGGTTCTGGCATCGATGAAGAACGCAGCGAAATGCGATAAGTAATGTGAATTGCAGAATTCAGTGAATCATCGAATCTTTGAACGCACATTGCGCCCCTTGGCATTCCGAGGGGCATACCTGTTCGAGCGTC---ATTGCA-CCCC-TCGAG----CCCTCTTT-------GGCTTGGTGTTGAGCTGC---GCGT---CCCTC------GGGACGGGCTCGAACGGCAGTGGC-GGTCCGG-CGTGCG-GGCAAGTGC-AGT-ACG-CAT-------------AAA-GCATTCGCTTG-AACGGCGCG--CCCGGG-TCCGGCCAGAC--AA----CAGCCTCCCC------GCAA------------------------TC--AACCCGTTTGACCTCGGATCAGGTAGGGATACCCGCTGAACTTAAGCATA\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "## Liz: also prepended ../ here\n",
    "####################################\n",
    "fasta_dict = read_fasta_file(\"../Data/Final_alignment_Mercado_Sticta2.fasta\") # Call newly created function\n",
    "list(fasta_dict.items())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Write a short function to get 3-letter codes for countries names\n",
    "One of the the parts that I was interested in reducing was the country name. These are pretty long. For this I wanted to exchange the long names for 3-letter code format names. To do this, I obtained from [datahub](https://datahub.io/dataset/iso-3166-1-alpha-2-country-codes/resource/9c3b30dd-f5f3-4bbe-a3cb-d7b2c21d66ce) a file that contained the names of all countries, their corresponding 3-letter codes, and other data. Since composite country names in this file were separated by a space (e.g. New Zealand) and the country names in my file were not, the function also needed to remove this space. Also, some \"countries\" in my FASTA file were not actual countries, but treated as independent political entities (e.g. Galapagos). Therefore I had to manually add some extra records and create new 3-letter codes to the file to account for these names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Liz: Manually adding entries works if there aren't many extra cases,\n",
    "## but in the future you could try automatically generating new codes\n",
    "## based on the full country name (grabbing first three letters, etc).\n",
    "##########################################\n",
    "def get_country_abbr_dict(country_csv_path):\n",
    "    '''\n",
    "    Read table containing three letter codes for countries (file: iso_3166_2_countries.csv)\n",
    "    and create dictionary with long names as keys and 3-letter codes as values\n",
    "    '''\n",
    "    with open(country_csv_path, \"r\") as f:\n",
    "        reader = csv.DictReader(f) \n",
    "        country_abbr_dict = {}\n",
    "        for row in reader:\n",
    "            name_w_spaces = row['Common Name']\n",
    "            name_no_space = ''.join(name_w_spaces.split()) # This variable executes a function that removes the spaces whenever\n",
    "                                                           # they are present\n",
    "            country_abbr_dict[name_no_space] = row['ISO 3166-1 3 Letter Code']  # Creates the dictionary\n",
    "    \n",
    "    return country_abbr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a peek a this dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abkhazia': 'GEO',\n",
       " 'Afghanistan': 'AFG',\n",
       " 'Aland': 'ALA',\n",
       " 'Alaska': 'ALK',\n",
       " 'Albania': 'ALB',\n",
       " 'Algeria': 'DZA',\n",
       " 'AmericanSamoa': 'ASM',\n",
       " 'Andorra': 'AND',\n",
       " 'Angola': 'AGO',\n",
       " 'Anguilla': 'AIA',\n",
       " 'AntiguaandBarbuda': 'ATG',\n",
       " 'Argentina': 'ARG',\n",
       " 'Armenia': 'ARM',\n",
       " 'Aruba': 'ABW',\n",
       " 'Ascension': 'ASC',\n",
       " 'AshmoreandCartierIslands': 'AUS',\n",
       " 'Australia': 'AUS',\n",
       " 'AustralianAntarcticTerritory': 'ATA',\n",
       " 'Austria': 'AUT',\n",
       " 'Azerbaijan': 'AZE',\n",
       " 'Azores': 'AZO',\n",
       " 'Bahamas,The': 'BHS',\n",
       " 'Bahrain': 'BHR',\n",
       " 'BakerIsland': 'UMI',\n",
       " 'Bangladesh': 'BGD',\n",
       " 'Barbados': 'BRB',\n",
       " 'Belarus': 'BLR',\n",
       " 'Belgium': 'BEL',\n",
       " 'Belize': 'BLZ',\n",
       " 'Benin': 'BEN',\n",
       " 'Bermuda': 'BMU',\n",
       " 'Bhutan': 'BTN',\n",
       " 'Bolivia': 'BOL',\n",
       " 'BosniaandHerzegovina': 'BIH',\n",
       " 'Botswana': 'BWA',\n",
       " 'BouvetIsland': 'BVT',\n",
       " 'Brazil': 'BRA',\n",
       " 'BritishAntarcticTerritory': 'ATA',\n",
       " 'BritishIndianOceanTerritory': 'IOT',\n",
       " 'BritishSovereignBaseAreas': '',\n",
       " 'BritishVirginIslands': 'VGB',\n",
       " 'Brunei': 'BRN',\n",
       " 'Bulgaria': 'BGR',\n",
       " 'BurkinaFaso': 'BFA',\n",
       " 'Burundi': 'BDI',\n",
       " 'Cambodia': 'KHM',\n",
       " 'Cameroon': 'CMR',\n",
       " 'Canada': 'CAN',\n",
       " 'CanaryIslands': 'CIL',\n",
       " 'CapeVerde': 'CPV',\n",
       " 'CaymanIslands': 'CYM',\n",
       " 'CentralAfricanRepublic': 'CAF',\n",
       " 'Chad': 'TCD',\n",
       " 'Chile': 'CHL',\n",
       " \"China,People'sRepublicof\": 'CHN',\n",
       " 'China,Republicof(Taiwan)': 'TWN',\n",
       " 'ChristmasIsland': 'CXR',\n",
       " 'ClippertonIsland': 'PYF',\n",
       " 'Cocos(Keeling)Islands': 'CCK',\n",
       " 'Colombia': 'COL',\n",
       " 'Comoros': 'COM',\n",
       " 'Congo,(Congo\\x96Brazzaville)': 'COG',\n",
       " 'Congo,(Congo\\x96Kinshasa)': 'COD',\n",
       " 'CookIslands': 'COK',\n",
       " 'CoralSeaIslands': 'AUS',\n",
       " 'CostaRica': 'CRI',\n",
       " \"Coted'Ivoire(IvoryCoast)\": 'CIV',\n",
       " 'Croatia': 'HRV',\n",
       " 'Cuba': 'CUB',\n",
       " 'Cyprus': 'CYP',\n",
       " 'CzechRepublic': 'CZE',\n",
       " 'DRCongo': 'DRC',\n",
       " 'Denmark': 'DNK',\n",
       " 'Djibouti': 'DJI',\n",
       " 'Dominica': 'DMA',\n",
       " 'DominicanRepublic': 'DOM',\n",
       " 'Ecuador': 'ECU',\n",
       " 'Egypt': 'EGY',\n",
       " 'ElSalvador': 'SLV',\n",
       " 'EquatorialGuinea': 'GNQ',\n",
       " 'Eritrea': 'ERI',\n",
       " 'Estonia': 'EST',\n",
       " 'Ethiopia': 'ETH',\n",
       " 'FalklandIslands(IslasMalvinas)': 'FLK',\n",
       " 'FaroeIslands': 'FRO',\n",
       " 'Fiji': 'FJI',\n",
       " 'Finland': 'FIN',\n",
       " 'France': 'FRA',\n",
       " 'FrenchGuiana': 'GUF',\n",
       " 'FrenchPolynesia': 'PYF',\n",
       " 'FrenchSouthernandAntarcticLands': 'ATF',\n",
       " 'Gabon': 'GAB',\n",
       " 'Galapagos': 'GAL',\n",
       " 'Gambia,The': 'GMB',\n",
       " 'Georgia': 'GEO',\n",
       " 'Germany': 'DEU',\n",
       " 'Ghana': 'GHA',\n",
       " 'Gibraltar': 'GIB',\n",
       " 'Greece': 'GRC',\n",
       " 'Greenland': 'GRL',\n",
       " 'Grenada': 'GRD',\n",
       " 'Guadeloupe': 'GLP',\n",
       " 'Guam': 'GUM',\n",
       " 'Guatemala': 'GTM',\n",
       " 'Guernsey': 'GGY',\n",
       " 'Guinea': 'GIN',\n",
       " 'Guinea-Bissau': 'GNB',\n",
       " 'Guyana': 'GUY',\n",
       " 'Haiti': 'HTI',\n",
       " 'HawaiiKauai': 'HKA',\n",
       " 'HawaiiMaui': 'HMA',\n",
       " 'HawaiiOahu': 'HOA',\n",
       " 'HeardIslandandMcDonaldIslands': 'HMD',\n",
       " 'Honduras': 'HND',\n",
       " 'HongKong': 'HKG',\n",
       " 'HowlandIsland': 'UMI',\n",
       " 'Hungary': 'HUN',\n",
       " 'Iceland': 'ISL',\n",
       " 'India': 'IND',\n",
       " 'Indonesia': 'IDN',\n",
       " 'Iran': 'IRN',\n",
       " 'Iraq': 'IRQ',\n",
       " 'Ireland': 'IRL',\n",
       " 'IsleofMan': 'IMN',\n",
       " 'Israel': 'ISR',\n",
       " 'Italy': 'ITA',\n",
       " 'Jamaica': 'JAM',\n",
       " 'Japan': 'JPN',\n",
       " 'JarvisIsland': 'UMI',\n",
       " 'Jersey': 'JEY',\n",
       " 'JohnstonAtoll': 'UMI',\n",
       " 'Jordan': 'JOR',\n",
       " 'Kazakhstan': 'KAZ',\n",
       " 'Kenya': 'KEN',\n",
       " 'KingmanReef': 'UMI',\n",
       " 'Kiribati': 'KIR',\n",
       " 'Korea,North': 'PRK',\n",
       " 'Korea,South': 'KOR',\n",
       " 'Kuwait': 'KWT',\n",
       " 'Kyrgyzstan': 'KGZ',\n",
       " 'Laos': 'LAO',\n",
       " 'Latvia': 'LVA',\n",
       " 'Lebanon': 'LBN',\n",
       " 'Lesotho': 'LSO',\n",
       " 'Liberia': 'LBR',\n",
       " 'Libya': 'LBY',\n",
       " 'Liechtenstein': 'LIE',\n",
       " 'Lithuania': 'LTU',\n",
       " 'Luxembourg': 'LUX',\n",
       " 'Macau': 'MAC',\n",
       " 'Macedonia': 'MKD',\n",
       " 'Madagascar': 'MDG',\n",
       " 'Malawi': 'MWI',\n",
       " 'Malaysia': 'MYS',\n",
       " 'Maldives': 'MDV',\n",
       " 'Mali': 'MLI',\n",
       " 'Malta': 'MLT',\n",
       " 'MarshallIslands': 'MHL',\n",
       " 'Martinique': 'MTQ',\n",
       " 'Mauritania': 'MRT',\n",
       " 'Mauritius': 'MUS',\n",
       " 'Mayotte': 'MYT',\n",
       " 'Mexico': 'MEX',\n",
       " 'Micronesia': 'FSM',\n",
       " 'MidwayIslands': 'UMI',\n",
       " 'Moldova': 'MDA',\n",
       " 'Monaco': 'MCO',\n",
       " 'Mongolia': 'MNG',\n",
       " 'Montenegro': 'MNE',\n",
       " 'Montserrat': 'MSR',\n",
       " 'Morocco': 'MAR',\n",
       " 'Mozambique': 'MOZ',\n",
       " 'Myanmar(Burma)': 'MMR',\n",
       " 'Nagorno-Karabakh': 'AZE',\n",
       " 'Namibia': 'NAM',\n",
       " 'Nauru': 'NRU',\n",
       " 'NavassaIsland': 'UMI',\n",
       " 'Nepal': 'NPL',\n",
       " 'Netherlands': 'NLD',\n",
       " 'NetherlandsAntilles': 'ANT',\n",
       " 'NewCaledonia': 'NCL',\n",
       " 'NewZealand': 'NZL',\n",
       " 'Nicaragua': 'NIC',\n",
       " 'Niger': 'NER',\n",
       " 'Nigeria': 'NGA',\n",
       " 'Niue': 'NIU',\n",
       " 'NorfolkIsland': 'NFK',\n",
       " 'NorthernCyprus': 'CYP',\n",
       " 'NorthernMarianaIslands': 'MNP',\n",
       " 'Norway': 'NOR',\n",
       " 'Oman': 'OMN',\n",
       " 'Pakistan': 'PAK',\n",
       " 'Palau': 'PLW',\n",
       " 'PalmyraAtoll': 'UMI',\n",
       " 'Panama': 'PAN',\n",
       " 'PapuaNewGuinea': 'PNG',\n",
       " 'Paraguay': 'PRY',\n",
       " 'Peru': 'PER',\n",
       " 'PeterIIsland': 'ATA',\n",
       " 'Philippines': 'PHL',\n",
       " 'PitcairnIslands': 'PCN',\n",
       " 'Poland': 'POL',\n",
       " 'Portugal': 'PRT',\n",
       " 'Pridnestrovie(Transnistria)': 'MDA',\n",
       " 'PuertoRico': 'PRI',\n",
       " 'Qatar': 'QAT',\n",
       " 'QueenMaudLand': 'ATA',\n",
       " 'Reunion': 'REU',\n",
       " 'Romania': 'ROU',\n",
       " 'RossDependency': 'ATA',\n",
       " 'Russia': 'RUS',\n",
       " 'Rwanda': 'RWA',\n",
       " 'SaintBarthelemy': 'GLP',\n",
       " 'SaintHelena': 'SHN',\n",
       " 'SaintKittsandNevis': 'KNA',\n",
       " 'SaintLucia': 'LCA',\n",
       " 'SaintMartin': 'GLP',\n",
       " 'SaintPierreandMiquelon': 'SPM',\n",
       " 'SaintVincentandtheGrenadines': 'VCT',\n",
       " 'Samoa': 'WSM',\n",
       " 'SanMarino': 'SMR',\n",
       " 'SaoTomeandPrincipe': 'STP',\n",
       " 'SaudiArabia': 'SAU',\n",
       " 'Scotland': 'SCT',\n",
       " 'Senegal': 'SEN',\n",
       " 'Serbia': 'SRB',\n",
       " 'Seychelles': 'SYC',\n",
       " 'SierraLeone': 'SLE',\n",
       " 'Singapore': 'SGP',\n",
       " 'Slovakia': 'SVK',\n",
       " 'Slovenia': 'SVN',\n",
       " 'SolomonIslands': 'SLB',\n",
       " 'Somalia': 'SOM',\n",
       " 'Somaliland': 'SOM',\n",
       " 'SouthAfrica': 'ZAF',\n",
       " 'SouthGeorgia&SouthSandwichIslands': 'SGS',\n",
       " 'SouthOssetia': 'GEO',\n",
       " 'Spain': 'ESP',\n",
       " 'SriLanka': 'LKA',\n",
       " 'Sudan': 'SDN',\n",
       " 'Suriname': 'SUR',\n",
       " 'Svalbard': 'SJM',\n",
       " 'Swaziland': 'SWZ',\n",
       " 'Sweden': 'SWE',\n",
       " 'Switzerland': 'CHE',\n",
       " 'Syria': 'SYR',\n",
       " 'Taiwan': 'TAI',\n",
       " 'Tajikistan': 'TJK',\n",
       " 'Tanzania': 'TZA',\n",
       " 'Thailand': 'THA',\n",
       " 'Timor-Leste(EastTimor)': 'TLS',\n",
       " 'Togo': 'TGO',\n",
       " 'Tokelau': 'TKL',\n",
       " 'Tonga': 'TON',\n",
       " 'TrinidadandTobago': 'TTO',\n",
       " 'TristandaCunha': 'TAA',\n",
       " 'Tunisia': 'TUN',\n",
       " 'Turkey': 'TUR',\n",
       " 'Turkmenistan': 'TKM',\n",
       " 'TurksandCaicosIslands': 'TCA',\n",
       " 'Tuvalu': 'TUV',\n",
       " 'U.S.VirginIslands': 'VIR',\n",
       " 'USA': 'USA',\n",
       " 'Uganda': 'UGA',\n",
       " 'Ukraine': 'UKR',\n",
       " 'UnitedArabEmirates': 'ARE',\n",
       " 'UnitedKingdom': 'GBR',\n",
       " 'UnitedStates': 'USA',\n",
       " 'Uruguay': 'URY',\n",
       " 'Uzbekistan': 'UZB',\n",
       " 'Vanuatu': 'VUT',\n",
       " 'VaticanCity': 'VAT',\n",
       " 'Venezuela': 'VEN',\n",
       " 'Vietnam': 'VNM',\n",
       " 'WakeIsland': 'UMI',\n",
       " 'Wales': 'WAL',\n",
       " 'WallisandFutuna': 'WLF',\n",
       " 'Yemen': 'YEM',\n",
       " 'Zambia': 'ZMB',\n",
       " 'Zimbabwe': 'ZWE'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "## Liz: added ../\n",
    "#######################################\n",
    "country_abbr_dict = get_country_abbr_dict(\"../Data/iso_3166_2_countries.csv\") # Call newly created function\n",
    "country_abbr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Write a function that takes as arguments the fasta dictionary with names and sequences and the dictionary with abbreviated names and return a dictionary with shortened names in keys and corresponding sequences as values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was perhaps the hardest part and the most important. I wanted to use different naming conventions for different parts of the names, therefore I had to use RegEx to separate the parts and treat them independently. There might be simpler ways to do them, but I really wanted to practice my RegEx!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get package needed\n",
    "import re\n",
    "\n",
    "def get_short_name_fasta_dict(fasta_dict, country_abbr_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Write a function that takes the fasta dictionary created in Step 1, the dictionary with abbreviated names from\n",
    "    Step 2, shortens the names and retuns a dictionary with shortened names keys and sequences as values\n",
    "    \"\"\"\n",
    "\n",
    "#First, use RegEx to extract different sections of the long names to facilitate data manipulation.\n",
    "\n",
    "    short_name_fasta_dict = {} # Create empty dictionary\n",
    "    for name, seq in fasta_dict.items():\n",
    "        ###############################################\n",
    "        ## Liz: Generally good practice to not name things \"tmp\" when possible\n",
    "        ## Could use \"first_name_part\", \"middle_name_part\", etc.\n",
    "        ###############################################\n",
    "        tmp = re.findall(r'^>.*?(?=_GB|_AF|_AB|_EU|_KC|_AY|_DQ)', name) # This RegEx extract the first portion of the name, until\n",
    "                                                                        # it hits one of these initials (e.g. GB)\n",
    "        tmp2 = re.findall(r'[^_\\W]+_[^_\\W]+_[^_\\W]+_[^_\\W]+$', name) # This RegEx extract the latter 4 words separated by \n",
    "                                                                     # underscores at the end of the name. Country name is\n",
    "                                                                     # the first element in this section\n",
    "        tmp3 = re.findall(r'GBXXXXXX\\_.+?(?=_)_.+?(?=_)|KC\\d+\\_.+?(?=_)_.+?(?=_)|' \\\n",
    "                      'AY\\d+\\_.+?(?=_)_.+?(?=_)|DQ\\d+\\_.+?(?=_)_.+?(?=_)|' \\\n",
    "                      'AF\\d+\\_.+?(?=_)_.+?(?=_)|AB\\d+\\_|EU\\d+\\_.+?(?=_)_.+?(?=_)', name) # This an extremely long RegEx \n",
    "                                                # (There must be a way to shorten this, I know) that I used extract the middle  \n",
    "                                                # portion of the name. After doing the exercise I realized I didn't needed to use \n",
    "                                                # this for now for my renaming purposes, however since it was a lot of work\n",
    "                                                # I really wanted to leave it in! :)\n",
    "                                                ###########################\n",
    "                                                ## Liz: I sure know that feeling!\n",
    "                                                ###########################\n",
    "\n",
    "# Then, create short names for all scientific names in the dataset. Use the variable created in the previous step which contains\n",
    "# only the species names (tmp)\n",
    "\n",
    "        split_names = tmp[0].split('_')   # Separate scientific names using underscores\n",
    "        base_name = split_names[0][0:2] + \"_\" + split_names[1][0:3] # Select the first letter of the first word, adds a new\n",
    "                                                                    # underscore and the first three letters of the second word.\n",
    "                                                                    # All names had to have this\n",
    "        \n",
    "# Since scientific names in the file have up to 5 words separated by underscores (e.g. Sticta_aff_beauvoisii_1), I used \n",
    "# conditional statements to create the new abbreviated scientific names based on their length. After the second word, I used\n",
    "# two letters to identify subsequent words in the names.\n",
    "#############################\n",
    "## Liz: you could handle this a little more elegantly with a for loop, which would handle any number of words\n",
    "##for i, sci_name in enumerate(split_names):\n",
    "##    if i == 0:\n",
    "##        final_name = sci_name[0:2]\n",
    "##    elif i == 1:\n",
    "##        final_name = final_name + sci_name[0:3]\n",
    "##    else:\n",
    "##        final_name = final_name + sci_name[0:2]\n",
    "##############################\n",
    "        if len(split_names) == 2:\n",
    "            final_name = base_name\n",
    "        elif len(split_names) == 3:\n",
    "            final_name = base_name + \"_\" + split_names[2][0:2]\n",
    "        elif len(split_names) == 4:\n",
    "            final_name = base_name + \"_\" + split_names[2][0:2] + \"_\" + split_names[3][0:2] \n",
    "        else:\n",
    "            final_name = base_name + \"_\" + split_names[2][0:2] + \"_\" + split_names[3][0:2] + \"_\" + split_names[4][0:2]\n",
    "\n",
    "# Now I need to substitute the country name in the original sequence ID with the 3 letter abbreviation of that country. To do\n",
    "# this I will use the previously created dictionary \"country_abbr_dict\" which is in this format {country name: 'abbreviation'}\n",
    " \n",
    "        sample_info = tmp2[0].split('_') # creates list with all info categories splitted. Recall\n",
    "                                         # that the first element in tmp2 has the country names\n",
    "        country_name = sample_info[0] # extract country names\n",
    "        country_name_abbr = country_abbr_dict[country_name] # Use variable \"country name\" as index to the country_abbr_dict\n",
    "                                                        # dictionary to get the country abbrev. for each sample\n",
    "        sample_info[0] = country_name_abbr # replace long country names in the lists with the corresponding abbreviations\n",
    "        sample_info_tmp = sample_info[0:3] # removes the string \"ITS\" from the lists \n",
    "        final_sample_info = \"_\".join(sample_info_tmp) # rejoins the abbreviations with the rest separated with an underscore\n",
    "    \n",
    "# Merge the shortened species name (final_name) with the new abbreviated sample info\n",
    "    \n",
    "        final_ID = final_name + \"_\" + final_sample_info\n",
    "\n",
    "# Now I need to create a new dictionary that has the new short names along with their corresponding sequences\n",
    "\n",
    "        short_name_fasta_dict[final_ID] = seq\n",
    "    \n",
    "    return short_name_fasta_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a quick look at how this new dictionary looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('>S_glo_COL_Moncada_4747',\n",
       " 'CGTAGGTGAACTTGCGGAAGGATCATTACCGAG--AGAGGCGTCCATGCACGCCTCGGGGG------CCCCGG----CCCCTA---TCTT--CGC-A-CCC-CGTGCAT-ACC-GTACC-GGT--GTTGCTTTGGCGGCGCGCAG-CCGCC---GGAGA----CCCGTC--AAACC-TC-CCG-TATC-G-ATGTCGTCCGAGTCCC-A-TCGTATAATCGAA-TAAAAA-CTTTCAACAACGGATCTCTTGGTTCTGGCATCGATGAAGAACGCAGCGAAATGCGATAAGTAATGTGAATTGCAGAATTCAGTGAATCATCGAATCTTTGAACGCACATTGCGCCCCTTGGTATTCCGAGGGGCATACCTGTCCGAGCGTC---ATTGCA-CCCC-TCGAG----CCCTCTCC-------GGCTTGGTGTTGAGCCGC---GCGT--CCCCCC------GGGACGGGCTCGAACGGCAGTGGC-GGTCCGG-CGCGCC-TGCAAGTGC-AGT-AGG-CAT---------------A-CCATCCGCTTG-AGCGGCGCG--CCCGGG-TCCGGCCAGAC--AA----CAGCCTCCCC------GCAA------------------------TC--AAACCGTCTGACCTCGGATCAGGTAGGGATACCCGCTGAACTTAAGCATA\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_name_fasta_dict = get_short_name_fasta_dict(fasta_dict, country_abbr_dict) # Call newly created function\n",
    "list(short_name_fasta_dict.items())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Create a function that writes the newly created dictionary in Step 3 to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last part aims to create a text file in the FASTA file format that may be used later for future phylogenetic analysis. It takes as input the dictionary created in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_seq_file (short_name_fasta_dict):\n",
    "    '''\n",
    "     Send new dictionary to file\n",
    "    '''\n",
    "    #####################\n",
    "    ## Liz: I might let this output file name be an additional argument to the function, maybe using\n",
    "    ## file_modified_fasta as a default\n",
    "    #####################\n",
    "    with open(\"file_modified_fasta\", \"w\") as f: # You can change here the name of the new file\n",
    "        for name, seq in short_name_fasta_dict.items():\n",
    "            f.write('{0}\\n{1}'.format(name, seq)) # Puts the name in the first line and the corresponding sequences just below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the first record in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">S_glo_COL_Moncada_4747 CGTAGGTGAACTTGCGGAAGGATCATTACCGAG--AGAGGCGTCCATGCACGCCTCGGGGG------CCCCGG----CCCCTA---TCTT--CGC-A-CCC-CGTGCAT-ACC-GTACC-GGT--GTTGCTTTGGCGGCGCGCAG-CCGCC---GGAGA----CCCGTC--AAACC-TC-CCG-TATC-G-ATGTCGTCCGAGTCCC-A-TCGTATAATCGAA-TAAAAA-CTTTCAACAACGGATCTCTTGGTTCTGGCATCGATGAAGAACGCAGCGAAATGCGATAAGTAATGTGAATTGCAGAATTCAGTGAATCATCGAATCTTTGAACGCACATTGCGCCCCTTGGTATTCCGAGGGGCATACCTGTCCGAGCGTC---ATTGCA-CCCC-TCGAG----CCCTCTCC-------GGCTTGGTGTTGAGCCGC---GCGT--CCCCCC------GGGACGGGCTCGAACGGCAGTGGC-GGTCCGG-CGCGCC-TGCAAGTGC-AGT-AGG-CAT---------------A-CCATCCGCTTG-AGCGGCGCG--CCCGGG-TCCGGCCAGAC--AA----CAGCCTCCCC------GCAA------------------------TC--AAACCGTCTGACCTCGGATCAGGTAGGGATACCCGCTGAACTTAAGCATA\n"
     ]
    }
   ],
   "source": [
    "create_new_seq_file(short_name_fasta_dict) # Call the newly created function\n",
    "\n",
    "with open(\"file_modified_fasta\", \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    i = 0\n",
    "    for row in reader:\n",
    "        for keys, values in row.items():\n",
    "            while i < 1:\n",
    "                print(keys, values)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! File is ready for use. Check the newly created text file in the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2.\n",
    "So I decided to keep playing with the data and thought that it would be neat to create a map that show points over every country that is represented in the sequences dataset. This can be later added to a future publication. To make it a little more complicated, I did some research and found a way to make the size of the points propotional to the number of times the country appears in the dataset. This would give us a visual idea if there are countries that might be overepresented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Create table with identifiers and corresponding countries\n",
    "The first thing to do was writing a function that created a table containing the unique identifier of each sequence in one column, extract the country and add it to another column. To do this I created a new function that actually recycled and modified some of the code I already did for the previous part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_geo_table(fasta_dict):\n",
    "    '''\n",
    "    Create table with identifiers in one column and countries in the second column\n",
    "    '''\n",
    "    with open(\"geo_table.csv\", \"w\") as geo_table:\n",
    "        for name, seq in fasta_dict.items():\n",
    "            stripped_name = name.strip(\"\\n\") # Strip by new line!\n",
    "            tmp = re.findall(r'[^_\\W]+_[^_\\W]+_[^_\\W]+_[^_\\W]+$', name) # Recycled RegEx to get the portion with the country name\n",
    "            country = tmp[0].split(\"_\")[0] # Split the name and indexing for the first element of the name\n",
    "            geo_table.write('{},{}\\n'.format(stripped_name, country)) # Write the new table in to the file geo_table.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how this table looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-30af4616c9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwrite_geo_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfasta_dict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Call the newly created function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;31m# Use pandas for better visualization of the table\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'geo_table.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "write_geo_table(fasta_dict) # Call the newly created function\n",
    "\n",
    "import pandas # Use pandas for better visualization of the table\n",
    "\n",
    "data = pandas.read_csv('geo_table.csv', header=None)\n",
    " \n",
    "data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now with this table we are ready to keep working on R!\n",
    "\n",
    "Open the Rmd file included in the **Data** folder to continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
